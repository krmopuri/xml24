---
layout: home
---
## (AI2100/AI5100) Deep Learning Course Contents

Starting from an artificial neuron model, the aim of this course is to understand feed forward and recurrent architectures of Artificial Neural Networks, all the way to the modern Deep Neural Networks. Specifically, we will discuss the basic Neuron models (McCulloch Pitts, Perceptron), Multi-Layer Perceptron (MLP), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN) (LSTM and GRU). We will understand the representational ability of these models along with how to train them using the Gradient Descent technique using the Backpropagation algorithm.Â Specifically, we will discuss various optimization algorithms such as Nesterov Accelerated Gradient Descent, Adam, AdaGrad and RMSProp, etc. Towards the end, students of this course get exposed to important deep learning frameworks from computer vision and Natural Language Processing such as encoder-decoder architecture, attention mechanism, etc.

## Logistics

**Class Room**: A-LH-1 (02.01.2023 to 15.01.2023 & 18.02.2023 to 02.05.2023), Auditorium (16.01.2023 to 17.02.2023)

**Timings**: Slot-B (Monday-10:00-10:55, Wednesday-09:00-09:55, Thursday-11:00-11:55)

Visit this page regularly for the updates and information regarding the course.<br>

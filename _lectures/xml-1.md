---
type: lecture
date: 2024-07-30
title: (xml-1) Introduction

# optional (Taxonomy, Scope, and Evaluation of Explainability)
# please use /static_files/notes directory to store notes
# thumbnail: /static_files/path/to/image.jpg

# optional
tldr: "Attending different notions and properties surrounding Explainability."
  
# optional
# set it to true if you don't want this lecture to appear in the updates section
hide_from_announcments: false

# optional
links: 
    #- url: /static_files/presentations/lec.zip
    #  name: notes
    #- url: /static_files/presentations/code.zip
    #  name: codes
    - url: https://docs.google.com/presentation/d/16Q6vGYCkRwyKRmrzdvdVy51qJ0So2xdvDqfYJRhO8cw/edit?usp=sharing
      name: slides
    #- url: /static_files/presentations/lec.zip
    #  name: other
---

**Suggested Readings:**
- [Ch-3.1 from Interpretable Machine Learning book by Christoph Molnar](https://christophm.github.io/interpretable-ml-book/interpretability-importance.html)
- [Towards A Rigorous Science of Interpretable Machine Learning, Doshi-Velez and Kim, 2017](http://arxiv.org/abs/1702.08608)
- [Interpretable machine learning: definitions, methods, and applications, Murdoch et al. 2019](https://arxiv.org/abs/1901.04592)
- [Explanation in artificial intelligence: Insights from the social sciences, Tim Miller, 2019](https://www.sciencedirect.com/science/article/pii/S0004370218305988)
- [Examples are not Enough, Learn to Criticize! Criticism for Interpretability, Kim et al. 2016](https://proceedings.neurips.cc/paper/2016/file/5680522b8e2bb01943234bce7bf84534-Paper.pdf)
